{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc37b3be-0b10-4997-a729-ca6b1cc28d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Getting started with DSPy on Databricks \n",
    "In this notebook, we'll go into **how** of using DSPy to build a non-optimized RAG app on Databricks, in the process of which we'll look at **why** we should use DSPy for building GenAI solutions on Databricks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73c55563-6d7b-4ebe-8328-4166ce6ac128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e8fb69-cb1b-4d39-8fb4-dde7fa37ffed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U dspy mlflow databricks-agents databricks-sdk==0.50.0 \n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5b5c164-bb83-47fd-b7f6-605aed605c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "import math\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from mlflow.models import ModelConfig\n",
    "\n",
    "from dspy.retrieve.databricks_rm import DatabricksRM\n",
    "\n",
    "# from databricks.agents.evals import generate_evals_df\n",
    "# from databricks.vector_search.client import VectorSearchClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2798860-c654-491b-b67f-087358f01df3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a17c96d4-3237-410b-b00b-05e819aebec1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config_file = \"config.yaml\"\n",
    "model_config = ModelConfig(development_config=config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df8e998e-3c99-48d9-96ec-5bf293e7aac1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "906305ca-ee25-4f22-9059-85928ee98e21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = model_config.get(\"catalog\")\n",
    "SCHEMA = model_config.get(\"schema\")\n",
    "\n",
    "VECTOR_SEARCH_ENDPOINT = model_config.get(\"vector_search_endpoint\")\n",
    "VECTOR_SEARCH_INDEX = model_config.get(\"vector_search_index\")\n",
    "index_path = f\"{CATALOG}.{SCHEMA}.{VECTOR_SEARCH_INDEX}\"\n",
    "\n",
    "model = model_config.get(\"chat_endpoint_name\")\n",
    "\n",
    "LM = f\"databricks/{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "142314eb-3a4f-4fcf-bba6-0af9f86a6e71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Why DSPy?\n",
    "You can build an LLM application without any frameworks, but using a framework reduces the amount of effort it takes to build an application.\n",
    "\n",
    "At a high level, all LLM frameworks offer some abstractions to help you modularize your application code. They provide interfaces for connecting to different LMs, tools & other services e.g. retrievers, etc.  \n",
    " \n",
    "While DSPy offers similar benefits to other LLM frameworks, it stands out in a few ways.\n",
    "\n",
    "The premise of DSPy is that it focuses on programming rather than prompting. This violates the mental model we all have of LLMs, because we're so used to interacting with LLMs using natural language. \n",
    "\n",
    "While this works really well for simple QnA that most of do with chatGPT daily, anyone who has built and put a GenAI application into production will know how incredibly time consuming developing and iterating on the prompt is. It becomes even more so when you want to compare different models, each of which may have different prompting guidelines.   \n",
    "\n",
    "One of the key that DSPy stands out from other frameworks is that it goes one step further than the other frameworks, by offering an abstraction for prompt engineering. \n",
    "\n",
    "This means that DSPy allows you to focus on the logic rather than language.\n",
    "\n",
    "By writing code instead of writing prompts:\n",
    "1. You focus on the logic rather than on forcing the model to behave a certain way\n",
    "2. It's easier and more intuitive to iterate and expand your implementation, e.g. add another output field\n",
    "\n",
    "### Signatures\n",
    "\n",
    "To understand how to do this, we first need to understand **[Signatures](https://dspy.ai/learn/programming/signatures/?h=signature)**. \n",
    "\n",
    "At a high level, the purpose of the Signature is to define the inputs and the outputs required from your program. By creating a Signature, you're taking a declarative approach to prompt engineering. One way to see the value of this is to think about the Databricks vision with DLT. Similarly to how DLT simplifies ETL by providing a declarative approach, DSPy simplifies GenAI workflows by providing a declarative approach. The same way a really experienced Spark engineer could spend a lot of time on building a pipeline which is as performant as DLT, a seasoned prompt engineer could invest time and energy into building a very good prompt, which may be as good as the one created by DSPy, but that comes at a cost of time and effort. \n",
    "\n",
    "The docs linked above go into a lot of detail on Signatures. Because we're looking at a simple RAG implementation, we'll be using an inline Signature in our example. However, you also have the option for creating class based Signatures which allow you to clarify the task in the docstring, and provide hints regarding the input or output fields. The key thing to remember is your Signature needs to be explicit about **what** you want your model to do, not **how**. Once you make this mental switch from imperative (prompting) to declarative (Signatures), writing DSPy programs becomes second nature.\n",
    "\n",
    "### Modules\n",
    "\n",
    "After writing your signature, the next step is to create a **[Module](https://dspy.ai/learn/programming/modules/)**. Modules are the building blocks of your programs. You want to consider having a Module for each logically independent component of your solution. DSPy provides some built-in Modules which you will typically compose into your own custom ones, as in the example below. Your custom Modules always need an `__init__` method and a `forward` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aacbb88-ea40-40d8-83bc-a286239b2e78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## RAG Module\n",
    "Let's start building a RAG module with DSPy. The syntax below with `dspy.Module` allows you to connect the pieces we need for a RAG app together. These are, our **retriever** (which is a wrapper around our Databricks vector search index) and a **generator** which itself uses one of DSPy's built-in Modules to generate the response based on the question and the retrieved context. \n",
    "\n",
    "Concretely, in the `__init__` method, you declare any sub-module you'll need, which in this case is just a `dspy.Predict('context, question -> response')` module that takes retrieved context, a question, and produces a response. In the `forward` method, you simply express any Python control flow you like, using your modules. In this case, we first invoke our retriever followed by `self.response_generator`.\n",
    "\n",
    "#### Note\n",
    "One key thing to note is that we've used the flag `for_mosaic_agent_true` set to True. We use this in 2 places - first we pass it to the retriever parameter `use_with_databricks_agent_framework`. This is needed to ensure the response object is a list of dictionaries compatible with Databricks agents. Without the flag the RM produces a [Prediction](https://dspy.ai/api/primitives/Prediction/) object. Additionally, we also use our flag to help specify how to parse the inputs when received as a ChatAgentMessage or a ChatModelMessage in the `forward` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d11483a-bcfb-43f6-a7bc-6e33fffe3859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "  def __init__(self, for_mosaic_agent=True): \n",
    "    # setup mlflow tracing\n",
    "    mlflow.dspy.autolog()\n",
    "\n",
    "    # setup flag indicating if the object will be deployed as a Mosaic Agent\n",
    "    self.for_mosaic_agent = for_mosaic_agent\n",
    "    self.lm = dspy.LM(LM, cache=False)\n",
    "\n",
    "    # setup the primary retriever pointing to the chunked documents\n",
    "    self.retriever = DatabricksRM(\n",
    "        databricks_index_name=index_path,\n",
    "        text_column_name=\"page_content\",\n",
    "        docs_id_column_name=\"unique_chunk_index\",\n",
    "        columns=[\"page_content\"],\n",
    "        k=5,\n",
    "        use_with_databricks_agent_framework=for_mosaic_agent\n",
    "    )\n",
    "    \n",
    "    self.response_generator = dspy.Predict(\"context, question -> response\")\n",
    "\n",
    "  def forward(self, question):\n",
    "    if self.for_mosaic_agent:\n",
    "      # When using a mosaic agent, questions can be of type ChatAgentMessage or (TODO: accept ChatModelMessage) \n",
    "      question = question[\"messages\"][-1][\"content\"]\n",
    "\n",
    "    context = self.retriever(\n",
    "        question\n",
    "    )\n",
    "\n",
    "    with dspy.context(lm=self.lm):\n",
    "      response = self.response_generator(context=context, question=question)\n",
    "\n",
    "      if self.for_mosaic_agent:\n",
    "        return response.response\n",
    "      return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2462da29-abd0-46b1-83ca-7b1dd8803796",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## GenAI Tracing via MLflow Autologging\n",
    "\n",
    "You'll notice on line 4 of cell 11, we've used `mlflow.dspy.autolog()`\n",
    "\n",
    "MLflow Tracing is a feature that enhances observability in Generative AI applications by capturing detailed information about the execution of services. It records inputs, outputs, and metadata for each step of a request, aiding in debugging and performance monitoring. Tracing is an incredibly valuable way to understand how and where to improve on your programs, as well as understand what's happening under the hood with DSPy. By simply using `mlflow.dspy.autolog()` you get detailed execution traces for you DSPy GenAI applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7190b877-913b-407f-af4e-4c61038b444b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Testing\n",
    "Lets test our RAG module and look at the mlflow trace in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbacff8f-1be5-4f14-b572-0338a1bed704",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rag = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32decc0c-3ff5-4d3b-a58a-6fddacce2b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = rag({'messages': [{'content': 'What features are included in the \"Machine learning tutorial\" notebook for the scikit-learn package?', 'role': 'user'}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61179dc4-7b8b-4f62-8af5-3a6a06736412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Under the hood\n",
    "The MLFlow trace helps us understand the steps DSPy took under the hood. Lets walk through the trace above to understand what happened to return the response we received. \n",
    "\n",
    "The trace shows the steps taken in *reverse order*, i.e. the last step is at the top of the trace. \n",
    "\n",
    "1. At the top level we have `RAG.forward`, in which you can see the inputs which were provided, and the outputs returned. \n",
    "2. This is followed by `DatabricksRM.forward`, the forward method of the `DatabricksRM` module we used to query our vector search index. This shows you the query sent to vector search and the documents and metadata returned.\n",
    "3. Finally, we have `Predict.forward`, the forward method of the `Predict` module we configured with the `Signature` we wrote. You can see the variable names we specified in our `Signature` defined in the Inputs and Outputs of the module. Within `Predict.forward` you'll notice 3 sub methods:\n",
    "    1. `ChatAdapter.format` - **[Adapters](https://dspy.ai/api/adapters/Adapter/)** are a layer within DSPy which handle structuring inputs and parsing structured outputs to fit your Signature.  \n",
    "    2. `LM.__call__` - the LLM call - here you can see the system prompt created by the DSPy module, the retrieved documents sent along with the prompt, and the response from the LLM. \n",
    "    3. `ChatAdapter.parse` - another Adapter method which at this point is formatting the response to match the outputs defined in the Signature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "729f9e5a-e110-4482-b6b7-1c6f51aafb86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation\n",
    "While we can see DSPy has done a lot of work for us, we often need to measure the quality of our solution. While DSPy offers it's own **[Evaluation](https://dspy.ai/learn/evaluation/overview/)** methods, which you can leverage within Databricks, in this notebook we're going to leverage Mosaic's AI Agent Evaluation to see how it works seamlessly with DSPy. \n",
    "\n",
    "Since we don't have a curated dataset to evaluate against, we're going to start by creating and saving a synthetic evaluation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1a3d0bb-84f7-4884-a7a8-18152fc71287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_table = model_config.get(\"eval_table\")\n",
    "eval_table_path = f\"{CATALOG}.{SCHEMA}.{eval_table}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b73b7460-ca2b-424a-a303-a4cfc400a832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create synthetic evaluation dataset and save to table\n",
    "- Uncomment cells 20 & 21 if you're running this notebook for the first time.\n",
    "- Comment cells 20 & 21 for subsequent runs when you want to reference the same evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efa5d564-7134-423a-b3b6-55b86af595f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##### Uncomment this cell if you're running the notebook for the first time. \n",
    "# docs_table = model_config.get(\"table\")\n",
    "# docs_table_path = f\"{CATALOG}.{SCHEMA}.{docs_table}\"\n",
    "\n",
    "# docs_df = spark.read.table(docs_table_path).selectExpr(\"page_content as content\", \"source as doc_uri\")\n",
    "# display(docs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fba47a3-7eb4-499a-b6ce-7b162e193437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##### Uncomment this cell if you're running the notebook for the first time\n",
    "# agent_description = \"\"\" \n",
    "# The agent is a RAG chatbot that answers questions about Databricks. The Agent has access to a corpus of Databricks documents, and its task is to answer the user's questions by retrieving the relevant docs from the corpus and synthesizing a helpful, accurate response.\n",
    "# \"\"\"\n",
    "\n",
    "# question_guidelines = \"\"\"\n",
    "# # User personas\n",
    "# - A developer who is new to the Databricks platform\n",
    "# - An experienced, highly technical Data Scientist or Data Engineer\n",
    "\n",
    "# # Example questions\n",
    "# - what API lets me parallelize operations over rows of a delta table?\n",
    "# - Which cluster settings will give me the best performance when using Spark?\n",
    "\n",
    "# # Additional Guidelines\n",
    "# - Questions should be succinct, and human-like\n",
    "# \"\"\"\n",
    "\n",
    "# num_evals = 100\n",
    "\n",
    "# evals = generate_evals_df(\n",
    "#     docs_df,\n",
    "#     num_evals=num_evals,\n",
    "#     agent_description=agent_description\n",
    "\n",
    "# )\n",
    "\n",
    "# eval_df = spark.createDataFrame(evals)\n",
    "\n",
    "# eval_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(eval_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f104086-64b0-493e-b2fd-ca30a51f64b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Load synthetic eval table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf4b8d16-06c2-4dec-b568-2206b447076c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_df = spark.table(eval_table_path)\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7bda9e8-5f4e-4783-8da8-3215d8d0ba09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Run evaluation\n",
    "\n",
    "We simply pass in the `rag` module we created and our evaluation dataset to the mlflow `evaluate` call, and we can see the results in the mlflow run under \"traces\". \n",
    "\n",
    "Please note that this is an engineered example and the focus of this notebook is not on the quality of the results (the vector search is quite poor for now!) but to show the dev flow with DSPy and the integration with Databricks native capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a646384-14d2-4a7c-9269-0a789268c3d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: https://docs.databricks.com/aws/en/generative-ai/agent-evaluation/evaluate-agent#option-4-local-function-in-the-notebook\n",
    "\n",
    "mlflow.evaluate(\n",
    "  model=rag,\n",
    "  data=eval_df,\n",
    "  model_type=\"databricks-agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e7bb38-70e8-41e2-9bcb-26626ce4ba96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "We've looked at how to:\n",
    "1. Write a Signature\n",
    "2. Create a module\n",
    "3. Use DSPy with Databricks' and Mosaic capabilities:\n",
    "  1. Vector search\n",
    "  2. MLflow tracing\n",
    "  3. Mosaic Agent Eval"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01_dspy_without_opt_rag_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
